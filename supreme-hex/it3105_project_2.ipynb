{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xXPAe9wni9II",
    "outputId": "104cd7be-abf4-48dc-ef20-2ed42323b838"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "! {sys.executable} --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xY0ssxVGnsdE",
    "outputId": "67487916-d8a8-48de-ec62-986052c41852"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)\n",
    "\n",
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-jYWHVmAATW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGvJjU00m2q2",
    "outputId": "30565b93-6cae-4564-b4e7-7f1651c6ec7a"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "username = input('Username: ')\n",
    "password = getpass('Password: ')\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJCXMRnHHe28",
    "outputId": "cea1aa7c-5012-4e37-d71f-059d0a203dfb"
   },
   "outputs": [],
   "source": [
    "! rm -r -f it3105\n",
    "! git clone https://{username}:{password}@github.com/akselbor/it3105.git\n",
    "! cp -r ./it3105/project-2/src/ ./\n",
    "! cp -r ./it3105/project-2/self-play/ ./\n",
    "! cp ./it3105/project-2/train.py ./\n",
    "! cp ./it3105/project-2/generate_samples.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v29qZVOGUTrV",
    "outputId": "6bafa73c-ae16-4b4d-daa8-8be38c6e52d8"
   },
   "outputs": [],
   "source": [
    "# Install rustup\n",
    "! curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs > rustup_install.sh\n",
    "! sudo sh rustup_install.sh -y\n",
    "\n",
    "# Source ~/.cargo/env to get cargo on path, and build project\n",
    "# The LD_PRELOAD=\"\" is needed due to a conflict between rust's shipped jemalloc and\n",
    "# the system allocator... which took way to long to figure out.\n",
    "! source $HOME/.cargo/env && cd ./self-play/ && LD_PRELOAD=\"\" cargo build --release\n",
    "\n",
    "# Copy the relevant target files into this directory\n",
    "! cp ./self-play/target/release/libself_play.so ./self_play.so\n",
    "! find . -path \"./self-play/target/release/*/out/libtensorflow.so.1\" -exec cp {} /lib/x86_64-linux-gnu/libtensorflow.so.1 \\;\n",
    "! find . -path \"./self-play/target/release/*/out/libtensorflow_framework.so.1\" -exec cp {} /lib/x86_64-linux-gnu/libtensorflow_framework.so.1 \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zenNVMrp1aJK",
    "outputId": "216724db-8719-4cc0-bf59-d35b8a282e58"
   },
   "outputs": [],
   "source": [
    "! mkdir /content/samples\n",
    "BASE_DIR = '/content/drive/MyDrive/OHT'\n",
    "SAMPLES_DIR = '/content/samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xc72MBm8m0Gt"
   },
   "outputs": [],
   "source": [
    "from src import games\n",
    "from src import actor\n",
    "from src import interactive\n",
    "import numpy as np\n",
    "from random import choice\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbIxrHZQDV48",
    "outputId": "6ad0d36a-3c7e-4098-a10b-8548720c84b8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def latest_version_number(prefix):\n",
    "    latest = -1\n",
    "    for filename in os.listdir(BASE_DIR):\n",
    "        if filename.startswith(prefix):\n",
    "            name, version = filename.split('-')\n",
    "            assert name == prefix\n",
    "            assert version.startswith('v')\n",
    "\n",
    "        version_number = int(version[1:])\n",
    "        if version_number > latest:\n",
    "            latest = version_number\n",
    "  \n",
    "    if latest == -1:\n",
    "        raise ValueError(f'no models with name {prefix}')\n",
    "\n",
    "    return latest\n",
    "\n",
    "def delete_samples_preceeding(number):\n",
    "    for filename in os.listdir(SAMPLES_DIR):\n",
    "        filenumber, *_ = filename.split('.')\n",
    "        try:\n",
    "            if int(filenumber) < number:\n",
    "                pass\n",
    "                ! rm -r -f {SAMPLES_DIR}/{filename}\n",
    "        except Exception as e:\n",
    "            print(f'could not delete file {filename}: {e}')\n",
    "\n",
    "latest_version_number('oht6x6resnet128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voLCAVg5MO3M",
    "outputId": "6f7f82ec-1bb9-4048-dd72-b93bd1e2f188"
   },
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "model = 'oht6x6resnet128'\n",
    "simulations = 500\n",
    "size = 6\n",
    "concurrents = 512 \n",
    "leaf_evaluation = 'value_fn'\n",
    "encoder = 'normalized'\n",
    "max_sample_sets = 20\n",
    "samples = concurrents * 11 * 3\n",
    "\n",
    "#print(f'expected sampling time â‰ˆ {4 * samples / (250 * 200 / simulations)}')\n",
    "\n",
    "# Parameters related to training the model.\n",
    "learning_rate = 0.02\n",
    "epochs_per_step = 1\n",
    "\n",
    "# The number of sample sets generated\n",
    "sample_sets_generated = 1# 0 #latest_version_number(model) + 1\n",
    "\n",
    "for current_version in count(latest_version_number(model)):\n",
    "    current_model_path = f'{BASE_DIR}/{model}-v{current_version}'\n",
    "    sample_set_path = f'{SAMPLES_DIR}/{sample_sets_generated}.json'\n",
    "    print(f'using model {current_model_path}')\n",
    "    ! python generate_samples.py --samples {samples}  --simulations {simulations} --model {current_model_path} --out {sample_set_path} --size {size} --concurrents {concurrents} --evaluation {leaf_evaluation} --encoder {encoder}\n",
    "    sample_sets_generated += 1\n",
    "\n",
    "    new_model_path = f'{BASE_DIR}/{model}-v{current_version + 1}'\n",
    "    samplesets = ' '.join(f'{SAMPLES_DIR}/{i}.json' for i in range(max(0, sample_sets_generated - max_sample_sets), sample_sets_generated))\n",
    "    ! python train.py --size {size} --model {current_model_path} --out {new_model_path} --data {samplesets} --lr {learning_rate} --epochs {epochs_per_step}\n",
    "    # TODO: only replace incumbent if a new version wins >= 55%.\n",
    "    delete_samples_preceeding(sample_sets_generated - max_sample_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FiwVD9zHm0G2"
   },
   "outputs": [],
   "source": [
    "def encoder(x, add_batch_axis=False):\n",
    "    tensor = games.hex.normalized_encoder(x)\n",
    "    #tensor = games.hex.current_player_encoder(x)\n",
    "    if add_batch_axis:\n",
    "        return tf.reshape(tensor, (1, *tensor.shape))\n",
    "    else:\n",
    "        return tensor\n",
    "\n",
    "def time_limit(seconds):\n",
    "    start = None\n",
    "    def inner(i):\n",
    "        global start\n",
    "        if i == 0:\n",
    "            start = time.time()\n",
    "        \n",
    "        return (time.time() - start) >= seconds\n",
    "    \n",
    "    return inner"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "it3105-project-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
